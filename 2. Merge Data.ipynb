{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used to merge the processed data together and create training, validation, and testing sets\n",
    "\n",
    "The goal is to create a big DataFrame containing data from 2016, 2017, and 2018 used for training.\n",
    "\n",
    "We will also process further the data for 2019 that will be used for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "import bz2\n",
    "# Removing scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressed_pickle(title, data):\n",
    "    with bz2.BZ2File('./data/output/' + title + '.pbz2', 'w') as f:\n",
    "        cPickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_pickle(file):\n",
    "    data = bz2.BZ2File(file, 'rb')\n",
    "    data = cPickle.load(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2016_data = decompress_pickle('./data/output/bixi_processed_2016.pbz2')\n",
    "_2017_data = decompress_pickle('./data/output/bixi_processed_2017.pbz2')\n",
    "_2018_data = decompress_pickle('./data/output/bixi_processed_2018.pbz2')\n",
    "_2019_data = decompress_pickle('./data/output/bixi_processed_2019.pbz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking number of stations. We notice they increase over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2016_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2017_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2018_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_2019_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intersect all the station codes together and list out the common ones. Those are the stations that existed between 2016 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2016_stations = np.array(list(_2016_data.keys()))\n",
    "_2017_stations = np.array(list(_2017_data.keys()))\n",
    "_2018_stations = np.array(list(_2018_data.keys()))\n",
    "_2019_stations = np.array(list(_2019_data.keys()))\n",
    "\n",
    "common_stations = np.intersect1d(np.intersect1d(np.intersect1d(_2017_stations, _2018_stations), _2019_stations), _2016_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_stations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if columns are the same. They differ because there are extra hot-encoded weather data on some years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4776, 32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2016_data[5002].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4722, 33)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2017_data[5002].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872, 37)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2018_data[5002].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4773, 34)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2019_data[5002].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the 2016, 2017, 2018, and 2019 data based on the common station codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bixi_all_data = {}\n",
    "\n",
    "for station_code in _2016_data:\n",
    "    if station_code in common_stations:\n",
    "        bixi_all_data[station_code] = _2016_data[station_code]\n",
    "\n",
    "for station_code in _2017_data:\n",
    "    if station_code in common_stations:\n",
    "        df = bixi_all_data[station_code]\n",
    "        new_concat = pd.concat([df, _2017_data[station_code]])\n",
    "        bixi_all_data[station_code] = new_concat\n",
    "\n",
    "for station_code in _2018_data:\n",
    "    if station_code in common_stations:\n",
    "        df = bixi_all_data[station_code]\n",
    "        new_concat = pd.concat([df, _2018_data[station_code]])\n",
    "        bixi_all_data[station_code] = new_concat\n",
    "\n",
    "for station_code in _2019_data:\n",
    "    if station_code in common_stations:\n",
    "        df = bixi_all_data[station_code]\n",
    "        new_concat = pd.concat([df, _2019_data[station_code]])\n",
    "        bixi_all_data[station_code] = new_concat     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the merge will create *nan* fields because some years are missing some weather information. We will replace all the *nan* values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_code in bixi_all_data:\n",
    "    bixi_all_data[station_code] = bixi_all_data[station_code].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour_trip_count          0\n",
       "Date/Time                0\n",
       "Year                     0\n",
       "Month                    0\n",
       "Day                      0\n",
       "Temp (°C)                0\n",
       "Dew Point Temp (°C)      0\n",
       "Rel Hum (%)              0\n",
       "Wind Dir (10s deg)       0\n",
       "Wind Spd (km/h)          0\n",
       "Visibility (km)          0\n",
       "Stn Press (kPa)          0\n",
       "Hour                     0\n",
       "Minute                   0\n",
       "Second                   0\n",
       "Day_of_year              0\n",
       "Blowing Snow             0\n",
       "Clear                    0\n",
       "Cloudy                   0\n",
       "Drizzle                  0\n",
       "Fog                      0\n",
       "Heavy Rain               0\n",
       "Ice Pellets              0\n",
       "Mainly Clear             0\n",
       "Moderate Rain            0\n",
       "Moderate Rain Showers    0\n",
       "Mostly Cloudy            0\n",
       "Rain                     0\n",
       "Rain Showers             0\n",
       "Snow                     0\n",
       "Snow Showers             0\n",
       "Thunderstorms            0\n",
       "Haze                     0\n",
       "Heavy Rain Showers       0\n",
       "Moderate Drizzle         0\n",
       "Blowing Dust             0\n",
       "Freezing Drizzle         0\n",
       "Freezing Rain            0\n",
       "Smoke                    0\n",
       "Snow Grains              0\n",
       "Moderate Snow            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bixi_all_data[5002].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data for training and trsting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bixi_data_2019 = {}\n",
    "bixi_data_2016_2017_2018 = {}\n",
    "\n",
    "for station_code in bixi_all_data:\n",
    "    _2019 = bixi_all_data[station_code][(bixi_all_data[station_code]['Year'] == 2019)]\n",
    "    rest = bixi_all_data[station_code][(bixi_all_data[station_code]['Year'] == 2018) | (bixi_all_data[station_code]['Year'] == 2017) | (bixi_all_data[station_code]['Year'] == 2016)]\n",
    "    \n",
    "    bixi_data_2019[station_code] = _2019\n",
    "    bixi_data_2016_2017_2018[station_code] = rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure the years are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019    4773\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bixi_data_2019[5002]['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    4872\n",
       "2016    4776\n",
       "2017    4722\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bixi_data_2016_2017_2018[5002]['Year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle('bixi_data_2019', bixi_data_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_pickle('bixi_data_2016_2017_2018', bixi_data_2016_2017_2018)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
